# From Liability to Learning Tool: AI in Historical Education
**Critical Thinking Through AI Interrogation**  
**Jelena Stricak** · *9 min read · Apr 23, 2025*

---

Despite these significant concerns, I’ve found that AI can serve as a valuable pedagogical tool when approached with appropriate caution. Rather than treating AI as a source of historical knowledge, educators can use it to develop students’ critical thinking skills.

In my own teaching practice, I now regularly assign exercises where students must fact-check AI-generated historical content against reliable primary and secondary sources. I instruct them to approach ChatGPT with the same critical eye they would apply to a 19th-century nationalist historian or a politically motivated chronicle — questioning biases, identifying unsupported claims, and tracing the origins of specific assertions.

This approach has yielded remarkable results. Students develop a more nuanced understanding of historical methodology and source criticism. They learn to identify the hallmarks of reliable historical scholarship and to distinguish between evidence-based claims and plausible-sounding speculation.

One particularly successful assignment involved asking students to compare ChatGPT’s account of the Irish Famine with contemporary newspaper reports, government documents, and modern scholarly analyses. Students were astonished by the AI’s tendency to present a politically sanitised narrative that downplayed British policy decisions while also fabricating specific relief measures that never existed.

I once asked an AI to explain the fall of the Byzantine Empire — and it gave me a dramatic but factually flawed story. The AI wove together a compelling narrative about the final siege of Constantinople, complete with vivid details about Emperor Constantine XI’s last stand and Ottoman Sultan Mehmed II’s triumph. The story flowed beautifully, but contained several fabricated ‘facts’, including an entirely fictional diplomatic exchange and incorrect dates for key events. This experience highlighted a profound challenge at the intersection of artificial intelligence and historical scholarship.


---

## The Digital Chronicler: How AI “Remembers” History

### Pattern Recognition vs. Historical Understanding
Large language models (LLMs) like ChatGPT don’t ‘know’ history in the way human historians do. Rather than understanding historical contexts, causality, or the nuanced interpretation of primary sources, these systems identify statistical patterns in vast datasets of text. They generate responses based on the most probable sequence of words given a particular prompt, not based on historical truth or accuracy.

This fundamental difference becomes apparent when we examine how AI handles historical queries. When asked about well-documented historical events with abundant digital sources — like World War II or the American Revolution — AI can often produce reasonably accurate summaries. However, when questioned about more obscure historical topics or asked to provide specific details, these systems frequently resort to what historians might recognise as a form of digital confabulation.

### The Gap-Filling Tendency
Perhaps the most troubling aspect of AI’s approach to history is its tendency to fill gaps in knowledge with plausible-sounding but fabricated information. This behaviour bears an uncanny resemblance to biased chroniclers throughout history who embellished their accounts to serve particular narratives or interests.

In one classroom exercise, I asked my students to use ChatGPT to research lesser-known figures from the English Civil War. The AI confidently provided detailed biographies — complete with birth dates, educational backgrounds, and specific contributions to key battles. When my students cross-referenced this information with academic databases and primary sources, they discovered that roughly 30% of these ‘facts’ were entirely fabricated. In some cases, the AI had merged details from different historical figures or extrapolated from limited information to create coherent but fictional narratives.

This gap-filling tendency is particularly problematic because it’s delivered with the same authoritative tone regardless of whether the information is factual or fabricated. Unlike human historians, who typically signal uncertainty with phrases like “evidence suggests” or “sources are unclear,” AI systems rarely express appropriate levels of doubt when venturing beyond established facts.

---

## Case Studies: When AI Rewrites History

### The Phantom Sources Problem
One of the most concerning patterns I’ve observed is what I call the **“phantom sources problem”** — AI’s tendency to cite non-existent or misrepresented sources to bolster its claims. In February 2025, I conducted a systematic review of ChatGPT’s responses to questions about Tudor England. In approximately 40% of responses, the AI cited books, articles, or academic papers that either don’t exist or don’t contain the information attributed to them.

This phenomenon creates a dangerous illusion of scholarly rigour. Students and even some researchers might accept these phantom citations without verification, potentially spreading misinformation through their own work.


### The Distortion of Historical Figures
Another troubling pattern emerges when AI attempts to represent historical figures’ perspectives or generate simulated dialogues with people from the past. These representations often reflect contemporary values and linguistic patterns rather than historically accurate worldviews.

In April 2025, the educational platform Humy.ai launched a feature allowing students to “chat” with historical figures like Winston Churchill, Frederick Douglass, and Nelson Mandela. While marketed as an educational tool, my analysis of these simulations revealed significant historical inaccuracies. The AI-generated Churchill, for instance, expressed views on decolonisation that were far more aligned with contemporary perspectives than with his documented opinions. Similarly, the simulated Frederick Douglass used vocabulary and conceptual frameworks that wouldn’t have been available in the 19th century.

### The Amplification of Dominant Narratives
AI systems tend to amplify mainstream historical narratives while marginalising alternative perspectives. This occurs because these models are trained primarily on widely available digital sources, which often reflect dominant cultural viewpoints rather than the full spectrum of historical interpretation.

This bias became evident when I compared AI responses to questions about British imperial history across different models. All systems consistently presented narratives that underrepresented indigenous perspectives and overemphasised European accounts. When asked about the colonisation of India, for instance, ChatGPT provided detailed information about British administrative structures and economic policies but offered minimal insight into Indian resistance movements or the lived experiences of those under colonial rule.

---

## From Liability to Learning Tool: AI in Historical Education

### Critical Thinking Through AI Interrogation
Despite these significant concerns, I’ve found that AI can serve as a valuable pedagogical tool when approached with appropriate caution. Rather than treating AI as a source of historical knowledge, educators can use it to develop students’ critical thinking skills.

### Teaching Digital Literacy Through Historical Practice
The challenges posed by AI-generated historical content offer an opportunity to integrate digital literacy into history education. By examining how AI systems process and reproduce historical information, students can develop critical skills applicable to the broader digital information landscape.

I’ve developed a framework for my students that combines traditional historical methods with digital literacy principles:

- **Source identification**: Identifying the ultimate sources of historical claims, whether from AI or human authors  
- **Corroboration**: Cross-checking information across multiple reliable sources  
- **Contextualisation**: Understanding how historical information is shaped by its original context and by the medium through which it’s transmitted  
- **Bias recognition**: Identifying how AI systems might amplify certain perspectives while minimising others  
- **Uncertainty awareness**: Recognising when historical knowledge is limited or contested, and being wary of overly confident assertions  

This framework helps students navigate not only AI-generated content but also the broader challenges of historical information in the digital age.

---

## The Historian’s Dilemma: Engaging with AI Responsibly

### Balancing Innovation and Accuracy
As historians and educators, we face a complex balancing act. On one hand, AI tools offer exciting possibilities for engaging students, processing large volumes of historical data, and making historical knowledge more accessible. On the other hand, these same tools risk undermining the fundamental values of historical scholarship — accuracy, transparency, and critical engagement with sources.

The American Historical Association’s *Statement on Standards of Professional Conduct* emphasises that “a reputation for trustworthiness” is perhaps the “single most precious professional asset” of historians. Maintaining this trustworthiness while incorporating AI into our teaching and research requires careful consideration and clear ethical boundaries.

In my own practice, I’ve established several principles for responsible engagement with AI:

- Never rely on AI-generated content without verification against reliable sources  
- Clearly distinguish between AI-assisted research processes and AI-generated content  
- Maintain transparency with students about the limitations and risks of AI tools  
- Use AI as a supplement to, not a replacement for, the traditional historical method  
- Continuously evaluate and update approaches as AI technology evolves  

---

## The Future of Historical Knowledge in an AI Age
Looking ahead, historians must take an active role in shaping how AI engages with historical knowledge. Rather than simply critiquing from the sidelines, we should advocate for AI systems that better reflect the values and methods of historical scholarship.

This might include developing specialised historical AI tools trained on carefully curated sources, creating better mechanisms for expressing uncertainty and historiographical debate, and designing systems that more transparently cite their sources. It also means educating the public about how to critically evaluate AI-generated historical content.

---

## Conclusion: Towards a Critical Symbiosis
The relationship between AI and historical knowledge remains fraught with challenges, but it also offers opportunities for innovation in how we teach and communicate about the past. By approaching AI as an unreliable narrator rather than an authoritative source, historians can harness its capabilities while mitigating its risks.

I now treat AI-generated historical content as a starting point for critical inquiry rather than an endpoint. I encourage students to ask: *What sources might this narrative be based on? What perspectives are missing? What claims require further verification?* This approach transforms AI from a potential threat to historical accuracy into a valuable tool for developing critical historical thinking.

As we navigate this evolving landscape, maintaining a healthy scepticism towards AI-generated historical content is not technophobia but rather an extension of the critical approach historians have always applied to their sources. Just as we would question a medieval chronicle or a politically motivated memoir, we must question the historical narratives generated by our newest digital chroniclers.

The future of historical knowledge in the age of AI will be determined not by the technology itself, but by how we choose to engage with it — critically, ethically, and with an unwavering commitment to the pursuit of historical truth in all its complexity.

We’re teaching the first generation who will learn history from machines that hallucinate. If that doesn’t terrify and inspire us to do better, nothing will.

---

## Bibliography
- Ames, M. G. (2023). *Artificial Intelligence in Education*. Educational Technology Research and Development, 71(2), 417–437.  
- Bender, E. M. et al. (2021). *On the Dangers of Stochastic Parrots*. FAccT, 610–623.  
- Caliskan, A. et al. (2017). *Semantics Derived Automatically from Language Corpora*. Science, 356(6334), 183–186.  
- Cukurova, M. et al. (2023). *AI and Education: Teacher and Student Agency*. London Review of Education, 21(1).  
- European Commission. (2023). *Digital Education Action Plan*. Publications Office.  
- Hunt, Lynn. (1996). *The French Revolution and Human Rights: A Brief Documentary History.* Boston: Bedford/St. Martin’s.  
- Kramer, S. N. (2021). *History Begins at Sumer.* Univ. Pennsylvania Press.  
- Luckin, R. et al. (2023). *Intelligence Unleashed.* Pearson.  
- Ong, W. J. (2022). *Orality and Literacy.* Routledge.  
- Ostrogorsky, George. (1968). *History of the Byzantine State.* Oxford: Blackwell.  
- Pew Research Center. (2023). *The Role of AI in Education.*  
- Scholasticus, Socrates. (1957). *Ecclesiastical History.* Translated by A.C. Zenos. Grand Rapids: Eerdmans.  
- Selwyn, N. (2022). *Education and Technology.* Bloomsbury.  
- Sphrantzes, George. (1980). *The Fall of the Byzantine Empire: A Chronicle.* Translated by Marios Philippides. Amherst: University of Massachusetts Press.  
- Trouillot, Michel-Rolph. (1995). *Silencing the Past: Power and the Production of History.* Boston: Beacon Press.  
- UNESCO. (2023). *AI and Education: Guidance for Policy-makers.*  
- Williamson, B. (2023). *Big Data in Education.* SAGE.  
